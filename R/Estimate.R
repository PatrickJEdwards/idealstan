#' Create data to run IRT model
#' 
#' To run an IRT model using \code{idealstan}, you must first process your data using the \code{id_make} function. 
#' 
#' @param score_data A data frame in long form, i.e., one row in the data for each 
#' measured score or vote in the data. 
#' @param outcome Column name of the outcome in \code{score_data}, default is \code{"outcome"}
#' @param person_id Column name of the person/legislator ID index in \code{score_data}, 
#' default is \code{'person_id'}
#' @param item_id Column name of the item/bill ID index in \code{score_data}, 
#' default is \code{'item_id'}
#' @param time_id Column name of the time values in \code{score_data}: 
#' optional, default is \code{'time_id'}
#' @param group_id Optional column name of a person/legislator group IDs (i.e., parties) in \code{score_data}. 
#' Optional, default is \code{'group_id'}
#' @param inflate If \code{TRUE}, the score matrix is set up to enable modeling of 
#' missing data/absences (\code{miss_val}) as an inflation model in \code{\link{id_estimate}}
#' @param person_cov A one-sided formula that specifies the covariates
#' in \code{score_data} that will be used to hierarchically model the person/legislator ideal points
#' @param group_cov A one-sided formula that specifies the covariates
#' in \code{score_data} that will be used to hierarchically model the person/legislator ideal points at the group level
#' @param item_cov A one-sided formula that specifies the covariates
#' in \code{score_data} that will be used to hierarchically model the 
#' discrimination parameters for the regular model
#' @param item_cov_miss A one-sided formula that specifies the covariates
#' in the dataset that will be used to hierarchically model the discrimination parameters for the
#' missing data model
#' @param person_data An optional data frame of additional information about the persons (legislators) used for plotting. 
#' Must have a
#' column of the same name as \code{person_id} to match back to the long data.
#' Suggested other columns include a \code{person.names} column containing names of
#'  persons (legislators) and optionally a \code{group} column with names of any groupings of 
#'  the persons (legislators), such as parties or blocs (used for visualization).
#' @param simul_data Optionally, data that has been generated by the \code{\link{id_sim_gen}} function.
#' @param miss_exog_val An integer or string indicating values that should be treated as exogenous missing values in the score (rollcall) data. This value must be included in the list of missing values \code{miss_val}.
#' @param item_data An optional data frame of item/bill labels and other information used for visualization. Should include \code{item.names} column 
#'  containing item/bill labels; other columns are optional.
#' @param miss_val The value (numeric or character) that indicate missing data/absences in the data. If there are multiple possible values, 
#'  pass along a numeric or character vector of all such values. If missing data is coded as \code{NA}, simply leave this parameter at the default, \code{NA}.
#' @param high_val The value (numeric or character) that indicate the highest ordinal outcome possible, such as yes in a vote dataset or correct in a test examination.
#'  If there are multiple possible values, 
#'  pass along a numeric or character vector of all such values.
#' @param low_val The value (numeric or character) that indicates the lowest ordinal outcome possible, such as no votes in a vote dataset or incorrect in a test examination.
#'  If there are multiple possible values, 
#'  pass along a numeric or character vector of all such values.
#' @param middle_val The value (numeric or character) that indicate values between the lowest and highest categories, such as abstention in voting data or "Neither Agree nor Disagree" in likert scales.
#'  If there are multiple possible values, 
#'  pass along a numeric or character vector of all such values in correct order (lower to higher values).
#'  If there are no middle values (binary outcome), set to \code{NULL}.
#' @param ordinal Whether or not the data contain ordinal responses. If \code{TRUE}, middle values/abstentions are used as a middle category in constructing the outcome.
#'  Otherwise the response is assumed to be binary (yes/no) or (correct/incorrect).
#'  @param continuous Whether or not the outcome/response is continuous. If it is, \code{miss_val} is recoded as the maximum of the outcome + 1.
#' @param exclude_level A vector of any values that should be treated as \code{NA} in the response matrix. 
#' Unlike the \code{middle_val} parameter, these values will be dropped from the data before estimation rather than modeled explicitly.
#' @param simulation If \code{TRUE}, simulated values are saved in the \code{idealdata} object for later plotting with the \code{\link{id_plot_sims}} function
#' @param include_pres If \code{FALSE} and \code{score_data} is a \code{rollcall} object, drop the first row which often represents tiebreaker votes cast by the Vice President in the US Senate.
#' @return A \code{idealdata} object that can then be used in the \code{\link{id_estimate}} function to fit a model.
#' @export
#' @import rstan
#' @import dplyr
#' @importFrom tidyr gather spread
#' @import bayesplot
#' @import rstantools
#' @import Rcpp
#' @import methods
#' @importFrom stats dbinom median plogis quantile reorder rexp rlnorm runif sd step rnorm
#' @useDynLib idealstan, .registration = TRUE
#' @examples 
#' # You can either use a pscl rollcall object or a vote/score matrix 
#' # where persons/legislators are in the rows
#' # and items/bills are in the columns
#' 
#' library(dplyr)
#' 
#' # First, using a rollcall object with the 114th Senate's rollcall votes:
#' 
#' data('senate114')
#' 
#' to_idealstan <-   id_make(score_data = senate114,
#' ordinal = FALSE,
#' include_pres=FALSE)
#' 
id_make <- function(score_data=NULL,
                    outcome='outcome',
                    person_id='person_id',
                    item_id='item_id',
                    time_id='time_id',
                    group_id='group_id',
                    simul_data=NULL,
                           person_cov=NULL,
                    group_cov=NULL,
                          varying_group_id=NULL,item_cov=NULL,
                           miss_cov=NULL,
                           miss_exog_val=NULL,
                           item_cov_miss=NULL,
                           person_data=data_frame(),item_data=NULL,
                           miss_val=NA,high_val=3L,low_val=1L,middle_val=2L,
                           ordinal=FALSE,
                    continuous=FALSE,time=NULL,
                           outcome_label_type='votes',
                           exclude_level=NULL,inflate=TRUE,simulation=FALSE,
                    include_pres=FALSE) {
  
  
  # make sure to ungroup it if it's a tidy data frame
  if('tbl' %in% class(score_data)) score_data <- ungroup(score_data)
  
  # test for input and quote
  
  outcome <- .check_quoted(outcome,quo(outcome))
  item_id <- .check_quoted(item_id,quo(item_id))
  time_id <- .check_quoted(time_id,quo(time_id))
  group_id <- .check_quoted(group_id,quo(group_id))
  person_id <- .check_quoted(person_id,quo(person_id))
  
  # rename data
  # IDs are made factors now so we can re-arrange indices when need be
  score_rename <- select(score_data,
                       outcome = !!outcome,
                       item_id = !!item_id,
                       person_id = !!person_id) %>% 
    mutate(item_id=factor(!! quo(item_id)),
           person_id=factor(!! quo(person_id)))
  
  if(!is.null(group_id)) {
    score_rename$group_id <- factor(pull(score_data,!!group_id))
  } else {
      score_rename$group_id <- factor("G")
    }
  if(!is.null(time_id)) {
    score_rename$time_id <- pull(score_data,!!time_id)
  } else {
    score_rename$time_id <- 1
  }
  
  # now we can make these all quosures again to use in NSE
  
  outcome <- quo(outcome)
  item_id <- quo(item_id)
  person_id <- quo(person_id)
  time_id <- quo(time_id)
  group_id <- quo(group_id)
  
  # see what the max time point is
  
  max_t <- max(as.numeric(factor(pull(score_rename,!!time_id))))
  num_person <- max(as.numeric(factor(pull(score_rename,!!person_id))))
  num_group <- try(max(as.numeric(factor(pull(score_rename,!!group_id)))))
  num_item <- max(as.numeric(factor(pull(score_rename,!!item_id))))
  
  # create data frames for all hierachical parameters
  
  if(!is.null(person_cov)) {

    personm <- model.matrix(person_cov,data=score_data)
    
    # need to check for missing data and remove any missing from IDs
    
    score_rename <- slice(score_rename,as.numeric(attr(personm,'dimnames')[[1]]))
    
    person_cov <- bind_cols(as_data_frame(personm),
                            select(score_rename,!! time_id,
                                   !!person_id))
    
    # convert to long form for function
    
    person_cov <- gather(person_cov,key = !! quo(labels),value = !!quo(variables),
                         -!!time_id,-!!person_id) %>% 
      distinct
    
    person_cov <- .create_array(input_matrix=person_cov,
                                row_var=person_id,
                                col_var_name=labels,
                                col_var_value=variables,
                                third_dim_var=time_id)
    
    # reorder to fit stan
    person_cov <- aperm(person_cov,c(3,1,2))
  } else {
    person_cov <- .create_array(matrix(rep(0,num_person),nrow=num_person,ncol=1),arr_dim=max_t)
    person_cov <- aperm(person_cov,c(3,1,2))
  }
  
  # separate parameters for group-level covariates
  
  if(!is.null(group_cov)) {
    
    groupm <- model.matrix(group_cov,data=score_data)
    
    # need to check for missing data and remove any missing from IDs
    
    score_rename <- slice(score_rename,as.numeric(attr(groupm,'dimnames')[[1]]))
    
    group_cov <- bind_cols(as_data_frame(groupm),
                            select(score_rename,!! time_id,
                                   !!group_id))
    
    # convert to long form for function
    
    group_cov <- gather(group_cov,key = !! quo(labels),value = !!quo(variables),
                         -!!time_id,-!!group_id) %>% 
      distinct
    
    group_cov <- .create_array(input_matrix=group_cov,
                                row_var=group_id,
                                col_var_name=labels,
                                col_var_value=variables,
                                third_dim_var=time_id)
    
    # reorder to fit stan
    group_cov <- aperm(group_cov,c(3,1,2))
  } else {
    group_cov <- .create_array(matrix(rep(0,num_group),nrow=num_group,ncol=1),arr_dim=max_t)
    group_cov <- aperm(group_cov,c(3,1,2))
  }
  
  if(!is.null(item_cov)) {
    
    itemm <- select(score_data, !!! all.vars(item_cov)) %>% 
      mutate(item_id=pull(score_rename,!!item_id)) %>% 
      distinct(!!item_id,.keep_all = T)
    
    item_cov <- model.matrix(item_cov,data=itemm)
  } else {
    item_cov <- matrix(rep(0,num_item),nrow=num_item,ncol=1) 
    }
  if(!is.null(item_cov_miss)) {
    itemm <- select(score_data, !!! all.vars(item_cov)) %>% 
      mutate(item_id=pull(score_rename,!!item_id)) %>% 
      distinct(!!item_id,.keep_all = T)
    
    item_cov_miss <- model.matrix(item_cov_miss,data=itemm)
  } else {
    item_cov_miss <- matrix(rep(0,num_item),nrow=num_item,ncol=1) 
  }
  
  # recode score/outcome
  
  if(ordinal==TRUE & inflate==TRUE) {
    votes <- c(low_val,middle_val,high_val,miss_val)
    vote_int <- as.integer(factor(votes,levels=votes))
    names(vote_int) <- votes
    vote_labels <-  c('No','Abstain','Yes','Absent')
    miss_val <- vote_int[length(vote_int)]
  } else if(ordinal==FALSE & inflate==TRUE) {
    votes <- c(low_val,high_val,miss_val)
    vote_int <- as.integer(factor(votes,levels=votes))
    names(vote_int) <- votes
    vote_labels <-  c('No','Yes','Absent')
    miss_val <- vote_int[length(vote_int)]
  } else if(ordinal==TRUE & inflate==FALSE)  {
    votes <- c(low_val,middle_val,high_val)
    vote_int <- as.integer(factor(votes,levels=votes))
    names(vote_int) <- votes
    vote_labels <-  c('No','Abstain','Yes')
    miss_val <- NA
  } else {
    votes <- c(low_val,high_val)
    vote_int <- as.integer(factor(votes,levels=votes))
    names(vote_int) <- votes
    vote_labels <-  c('No','Yes')
    miss_val <- NA
  }
  
  if(continuous==FALSE) {
    score_rename <- mutate(score_rename,!! quo_name(outcome) := as.integer(factor(!!outcome,
                                                                                  levels=votes)))
  } else if(continuous==TRUE & inflate==TRUE) {
    max_val <- max(pull(score_rename,!!outcome))
    if(is.na(miss_val)) {
      score_rename <- mutate(score_rename,!! quo_name(outcome) := coalesce(is.na(!!outcome),max_val+1))
    } else {
      score_rename <- mutate(score_rename,!! quo_name(outcome) := ifelse(!!outcome==miss_val,max_val+1))
    }
    miss_val <- max_val+1
  } 
  
  
  
  # make roll calls a separate function
  
  if(class(score_data)=='rollcall') {
    miss_val <- 9
    low_val <- 6
    high_val <- 1
    exclude_level <- c(3,7)
    row_names <- row.names(score_data$legis.data)
    if(include_pres==F) {
      person_data <- slice(score_data$legis.data,-1)
      row_names <- row_names[-1]
    } else {
      person_data <- score_data$legis.data
    }
    
    person_data <-  mutate(person_data,group=party,person.names=row_names)
    
    if(include_pres==F) {
      score_matrix <- score_data$votes[-1,]
    } else {
      score_matrix <- score_data$votes
    }
    
    row.names(score_matrix) <- row_names
  } 
  
  if(nrow(person_data)==0) {
    person_data <- data_frame(person.names=as.character(1:num_person))
  }
  
  if(!("group" %in% names(person_data))) person_data$group <- rep('O',num_person)
  
  
  # check what kind of vote labels to use
  
  if(outcome_label_type=='none') {
    vote_labels <- as.character(vote_int)
  } else if(outcome_label_type!='votes') {
    vote_labels <- outcome_label_type
  }

  outobj <- new('idealdata',
      score_matrix=score_rename,
      person_data=person_data,
      person_cov=person_cov,
      group_cov=group_cov,
      item_cov=item_cov,
      item_cov_miss=item_cov_miss,
      vote_labels=vote_labels,
      vote_int=vote_int,
      vote_count=length(votes) - length(exclude_level),
      miss_val=miss_val)
  
  if(simulation==TRUE) {
    outobj@simul_data <- simul_data
    outobj@simulation <- simulation
  }
  return(outobj)
}

#' Estimate an \code{idealstan} model
#' 
#' This function will take a pre-processed \code{idealdata} vote/score matrix and run one of the available IRT models on the data using
#' Stan's MCMC engine.
#' 
#' To run an IRT ideal point model, you must first pre-process your data using the \code{\link{id_make}} function. Be sure to specify the correct options for the
#' kind of model you are going to run: if you want to run an ordinal and/or an inflated model, the data needs to be processed differently.
#' As of this version of \code{idealstan}, the following model types are available:
#' \enumerate{
#'   \item IRT 2-PL (binary response) ideal point model, no absence inflation
#'   \item IRT 2-PL model (binary response) with absence inflation
#'   \item Ordinal IRT (rating scale) model incorporating abstentions as middle category, no absence inflation
#'   \item Ordinal IRT (rating scale) model incorporating abstentions as middle category with absence inflation
#' }
#' Additional models are available but have not yet been tested. You can find them by searching the included stan files for more info.
#' @section Identification:
#' Identifying IRT models is challenging, and ideal point models are still more challenging because the discrimination parameters are not constrained.
#' As a result, more care must be taken to obtain estimates that are the same regardless of starting values. 
#' The parameter \code{fixtype} enables you to change the type of identification used. The default, 'vb', does not require any further
#' information from you in order for the model to be fit. In this version of identification, an unidentified model is run using
#' variational Bayesian inference (see \code{\link[rstan]{vb}}). If \code{restrict_type} is set to 'constrain_oneway', then the \code{nfix}
#' highest legislators/persons (if \code{restrict_params} is 'person') or bills/items (if \code{restrict_params} equals 'items') 
#' are used to constrain and identify the model. If \code{restrict_type} is set to 'constrain_twoway', then \code{nfix} highest and lowest legislators/persons
#' or bills/items are used to constrain and identify the model.
#' In addition, if \code{fixtype='vb'} is used, \code{auto_id} can be set to \code{TRUE}. This will run additional variational Bayesian models
#' using the identification achieved and will see if the signs of the estimated parameters are at least 90 percent in the same direction. If so, 
#' the model is considered identified. If not, the function will re-run and will increase \code{nfix} by one to see if that will identify the model, 
#' ad infinitum.
#' If \code{fixtype} is set to 'constrained', then identification is achieved by constraining a specified list of legislators/persons or
#' bills/items. If \code{restrict_type} is 'constrain_oneway', then the indices of all constrained legislators/persons or bills/items
#' should be included as the row or column indices of these parameters in the response matrix as a vector in \code{restrict_ind_high}.
#' If \code{restrict_type} is 'constrain_twoway,' then the indices of high constrained parameters should go in 
#' \code{restrict_ind_high} and the indices of low constrained parameters in \code{restrict_ind_low}. The numbers of high and low
#' constrained parameters should be equal. To pick the parameter to constrain, set \code{restrict_params} to 'person' for legislators/persons,
#' 'discrim_miss' for absence-inflated bill discrimination parameters, and 'discrim_reg' for non-inflated bill discrimination parameters.
#' If \code{fixtype} is set to 'pinned', then identification is achieved via pinning with very tight priors a set of legislators/persons or bills/items.
#' The indices of legislators/persons (i.e. row indices in the response matrix) or bills/items (column indices in the response matrix) should be passed as a vector
#' to \code{restrict_ind_high}, while \code{restrict_ind_low} should be left blank. The particular values to pin these parameters is passed as a 
#' numeric vector to \code{pin_vals}.
#' @param idealdata An object produced by the \code{\link{id_make}} containing a score/vote matrix for use for estimation & plotting
#' @param model_type An integer reflecting the kind of model to be estimated. See below.
#' @param use_subset Whether a subset of the legislators/persons should be used instead of the full response matrix
#' @param sample_it Whether or not to use a random subsample of the response matrix. Useful for testing.
#' @param subset_group If person/legislative data was included in the \code{\link{id_make}} function, then you can subset by
#' any value in the \code{$group} column of that data if \code{use_subset} is \code{TRUE}.
#' @param subset_person A list of character values of names of persons/legislators to use to subset if \code{use_subset} is 
#' \code{TRUE} and person/legislative data was included in the \code{\link{id_make}} function with the required \code{$person.names}
#' column
#' @param sample_size If \code{sample_it} is \code{TRUE}, this value reflects how many legislators/persons will be sampled from
#' the response matrix
#' @param nchains The number of chains to use in Stan's sampler. Minimum is one. See \code{\link[rstan]{stan}} for more info.
#' @param niters The number of iterations to run Stan's sampler. Shouldn't be set much lower than 500. See \code{\link[rstan]{stan}} for more info.
#' @param use_vb Whether or not to use Stan's variational Bayesian inference engine instead of full Bayesian inference. Pros: it's much faster.
#' Cons: it's not quite as accurate. See \code{\link[rstan]{vb}} for more info.
#' @param nfix An integer specifying the number of parameters to constrain (for both high and low) if \code{fixtype} is set to \code{'vb'}
#' @param warmup The number of iterations to use to calibrate Stan's sampler on a given model. Shouldn't be less than 100. 
#' See \code{\link[rstan]{stan}} for more info.
#' @param ncores The number of cores in your computer to use for parallel processing in the Stan engine. 
#' See \code{\link[rstan]{stan}} for more info.
#' @param fixtype Sets the particular kind of identification used on the model, could be one of 'vb' or 'constrained'.
#'  See details for more information.
#' @param id_diff The fixed difference between the high/low person/legislator ideal points used to identify the model. 
#' Set at 4 as a standard value but can be changed to any arbitrary number without affecting model results besides re-scaling.
#' @param id_diff_high The fixed intercept of the high ideal point used to constrain the model. 
#' @param use_ar If \code{TRUE}, will estimate time-varying parameters for legislators/persons with an AR(1) prior 
#' (implying 
#' the ideal points are stationary over time). Otherwise the model
#'  will estimate a random-walk process for the ideal points.
#' @param sample_stationary If \code{TRUE}, the AR(1) coefficients in a time-varying model will be 
#' sampled from an unconstrained space and then mapped back to a stationary space. Leaving this \code{TRUE} is 
#' slower but will work better when there is limited information to identify a model. If used, the
#' \code{ar_sd} parameter should be increased to 5 to allow for wider sampling in the unconstrained space.
#' @param ar_sd If an AR(1) model is used, this defines the prior scale of the Normal distribution. A lower number 
#' can help 
#' identify the model when there are few time points.
#' @param use_groups If \code{TRUE}, group parameters from the person/legis data given in \code{\link{id_make}} will be 
#'  estimated instead of individual parameters. 
#' @param restrict_ind_high If \code{fixtype} is not "vb", the particular indices of legislators/persons or bills/items to constrain high
#' @param restrict_ind_low If \code{fixtype} is not "vb", the particular indices of legislators/persons or bills/items to constrain low. 
#' (Note: not used if values are pinned).
#' @param discrim_reg_sd Set the prior standard deviation of the bimodal prior for the discrimination parameters for the non-inflated model.
#' @param discrim_miss_sd Set the prior standard deviation of the bimodal prior for the discrimination parameters for the inflated model.
#' @param person_sd Set the prior standard deviation for the legislators (persons) parameters
#' @param time_sd The precision (inverse variance) of the over-time component of the person/legislator
#' parameters. A higher value will allow for less over-time variation (useful if estimates bounce too much). 
#' Default is 4.
#' @param diff_reg_sd Set the prior standard deviation for the bill (item) intercepts for the non-inflated model.
#' @param diff_miss_sd Set the prior standard deviation for the bill (item) intercepts for the inflated model.
#' @param restrict_sd Set the prior standard deviation for constrained parameters
#' @param restrict_low_bar Set the constraint threshold for constrained parameters (parameter must be lower than this bar and no greater than zero)
#' @param restrict_high_bar Set the constraint threshold for constrained parameters (parameter must be higher than this bar and no less than zero)
#' @param ... Additional parameters passed on to Stan's sampling engine. See \code{\link[rstan]{stan}} for more information.
#' @return A fitted \code{\link{idealstan}} object that contains posterior samples of all parameters either via full Bayesian inference
#' or a variational approximation if \code{use_vb} is set to \code{TRUE}. This object can then be passed to the plotting functions for further analysis.
#' @seealso \code{\link{id_make}} for pre-processing data,
#' \code{\link{id_plot_legis}} for plotting results,
#' \code{\link{summary}} for obtaining posterior quantiles,
#' \code{\link{posterior_predict}} for producing predictive replications.
#' @examples
#' # First we can simulate data for an IRT 2-PL model that is inflated for missing data
#' library(ggplot2)
#' library(dplyr)
#' 
#' # This code will take at least a few minutes to run 
#' \dontrun{
#' bin_irt_2pl_abs_sim <- id_sim_gen(ordinal=FALSE,
#'                                   absence=TRUE,
#'                                   absence_diff_mean=0)
#' 
#' # Now we can put that directly into the id_estimate function 
#' # to get full Bayesian posterior estimates
#' # We will constrain discrimination parameters 
#' # for identification purposes based on the true simulated values
#' 
#' bin_irt_2pl_abs_est <- id_estimate(bin_irt_2pl_abs_sim,
#'                        model_type=2,
#'                        restrict_ind_high = 
#'                        sort(bin_irt_2pl_abs_sim@simul_data$true_reg_discrim,
#'                        decreasing=TRUE,
#'                        index=TRUE)$ix[1:3],
#'                        restrict_ind_low = 
#'                        sort(bin_irt_2pl_abs_sim@simul_data$true_reg_discrim,
#'                        decreasing=FALSE,
#'                        index=TRUE)$ix[1:3],
#'                        restrict_params = 'discrim_reg', 
#'                        restrict_type = 'constrain_twoway',
#'                        fixtype='constrained',
#'                        ncores=2,
#'                        nchains=2)
#'                                    
#' # We can now see how well the model recovered the true parameters
#' 
#' id_sim_coverage(bin_irt_2pl_abs_est) %>% 
#'          bind_rows(.id='Parameter') %>% 
#'          ggplot(aes(y=avg,x=Parameter)) +
#'            stat_summary(fun.args=list(mult=1.96)) + 
#'            theme_minimal()
#'  }
#' 
#' # In most cases, we will use pre-existing data 
#' # and we will need to use the id_make function first
#' # We will use the full rollcall voting data 
#' # from the 114th Senate as a rollcall object
#' 
#' data('senate114')
#' 
#' # Running this model will take at least a few minutes, even with 
#' # variational inference (use_vb=T) turned on
#' \dontrun{
#' 
#' to_idealstan <-   id_make(score_data = senate114,
#'                           ordinal = FALSE,
#'                           include_pres=FALSE)
#' 
#' sen_est <- id_estimate(senate_data,
#' model_type = 2,
#' use_vb = TRUE,
#' restrict_type='constrain_oneway',
#' restrict_params='person',
#' restrict_ind_high = which(row.names(senate114$votes[-1,])=='SASSE (R NE)'),
#' auto_id=FALSE,
#' fixtype='constrained')
#' 
#' # After running the model, we can plot 
#' # the results of the person/legislator ideal points
#' 
#' id_plot_legis(sen_est)
#' }
#' 
#' @references \enumerate{
#'    \item Clinton, J., Jackman, S., & Rivers, D. (2004). The Statistical Analysis of Roll Call Data. \emph{The American Political Science Review}, 98(2), 355-370. doi:10.1017/S0003055404001194
#'    \item Bafumi, J., Gelman, A., Park, D., & Kaplan, N. (2005). Practical Issues in Implementing and Understanding Bayesian Ideal Point Estimation. \emph{Political Analysis}, 13(2), 171-187. doi:10.1093/pan/mpi010
#' }
#' @export
id_estimate <- function(idealdata=NULL,model_type=2,use_subset=FALSE,sample_it=FALSE,
                           subset_group=NULL,subset_person=NULL,sample_size=20,
                           nchains=4,niters=2000,use_vb=FALSE,nfix=3,
                           restrict_ind_high=NULL,
                          id_diff=4,
                        id_diff_high=2,
                           restrict_ind_low=NULL,
                           fixtype='vb',warmup=floor(niters/2),ncores=4,
                           auto_id=FALSE,
                          use_ar=FALSE,
                        use_groups=FALSE,
                           discrim_reg_sd=3,
                           discrim_miss_sd=3,
                           person_sd=1,
                        time_sd=4,
                        sample_stationary=FALSE,
                        ar_sd=2,
                           diff_reg_sd=4,
                           diff_miss_sd=4,
                           restrict_sd=0.1,
                           restrict_low_bar=0,
                        restrict_high_bar=0,
                           ...) {

  
  if(use_subset==TRUE || sample_it==TRUE) {
    idealdata <- subset_ideal(idealdata,use_subset=use_subset,sample_it=sample_it,subset_group=subset_group,
                              subset_person=subset_person,sample_size=sample_size)
  }
  

    #hier_type <- suppressWarnings(.get_hier_type(idealdata))
    idealdata@stanmodel <- stanmodels[['irt_standard']]
   
    #Using an un-identified model with variational inference, find those parameters that would be most useful for
    #constraining/pinning to have an identified model for full Bayesian inference
    
  # use either row numbers for person/legislator IDs or use group IDs (static or time-varying)
      
  if(use_groups==T) {
    legispoints <- as.numeric(idealdata@score_matrix$group_id)
    num_legis <- max(legispoints)
    # this handles the situation in which the data is fake and only 
    # groups are used as parameters
    legis_pred <- idealdata@group_cov
  } else {
    legispoints <- as.numeric(idealdata@score_matrix$person_id)
    num_legis <- max(legispoints)
    legis_pred <- idealdata@person_cov
  }

  billpoints <- as.numeric(idealdata@score_matrix$item_id)
  timepoints <- as.numeric(factor(idealdata@score_matrix$time_id))
  
  num_bills <- max(billpoints)

  Y <- idealdata@score_matrix$outcome
  
  # check to see if we need to recode missing values from the data if the model_type doesn't handle missing data
  if(model_type %in% c(1,3,5,7,9,11) & !is.na(idealdata@miss_val)) {
    Y <- na_if(Y,idealdata@miss_val)
  }
  
  # check to see if more values than there should be for the bernoulli model
  
  if(model_type==1 && length(table(Y))>2) {
    stop('Too many values in score matrix for a binary model. Choose a different model_type.')
  } else if(model_type==2 && length(table(Y))>3) {
    stop("Too many values in score matrix for a binary model. Choose a different model_type.")
  }

  #Remove NA values, which should have been coded correctly in the make_idealdata function
  
    remove_nas <- !is.na(Y)
    Y <- Y[remove_nas]

    legispoints <- legispoints[remove_nas]
    billpoints <- billpoints[remove_nas]
    timepoints <- timepoints[remove_nas]
    
  if(model_type>8) {
    N_cont <- length(Y)
    N_int <- 1L
    Y_cont <- Y
    Y_int <- 1L
  } else {
    N_cont <- 1L
    N_int <- length(Y)
    Y_cont <- 1
    Y_int <- as.integer(Y)
  }

  this_data <- list(N=length(Y),
                    N_cont=N_cont,
                    N_int=N_int,
                    Y_int=Y_int,
                    Y_cont=Y_cont,
                    T=max(timepoints),
                    num_legis=max(legispoints),
                    num_bills=num_bills,
                    ll=legispoints,
                    bb=billpoints,
                    time=timepoints,
                    LX=dim(idealdata@person_cov)[3],
                    SRX=ncol(idealdata@item_cov),
                    SAX=ncol(idealdata@item_cov_miss),
                    legis_pred=legis_pred,
                    srx_pred=idealdata@item_cov,
                    sax_pred=idealdata@item_cov_miss,
                    model_type=model_type,
                    discrim_reg_sd=discrim_reg_sd,
                    discrim_abs_sd=discrim_miss_sd,
                    legis_sd=person_sd,
                    diff_reg_sd=diff_reg_sd,
                    diff_abs_sd=diff_miss_sd,
                    restrict_sd=restrict_sd,
                    restrict_low_bar=restrict_low_bar,
                    restrict_high_bar=restrict_high_bar,
                    use_ar=as.integer(use_ar),
                    time_sd=time_sd,
                    ar_sd=ar_sd)

  idealdata <- id_model(object=idealdata,fixtype=fixtype,model_type=model_type,this_data=this_data,
                        nfix=nfix,restrict_ind_high=restrict_ind_high,
                        restrict_ind_low=restrict_ind_low,
                        auto_id=auto_id,
                        ncores=ncores,
                        use_groups=use_groups)
  
  # if diff hasn't been set yet, set it
  
  if(length(idealdata@diff_high)==0) {
      idealdata@diff <- id_diff
      idealdata@diff_high <- id_diff_high
  }
  
  # now run an identified run
  # repeat data formation as positions of rows/columns may have shifted
  if(use_groups==T) {
    legispoints <- as.numeric(idealdata@score_matrix$group_id)
    num_legis <- max(legispoints)
  } else {
    legispoints <- as.numeric(idealdata@score_matrix$person_id)
    num_legis <- max(legispoints)
  }
  
  billpoints <- as.numeric(idealdata@score_matrix$item_id)
  timepoints <- as.numeric(factor(idealdata@score_matrix$time_id))
  
  num_bills <- max(billpoints)
  
  Y <- idealdata@score_matrix$outcome
  
  # check to see if we need to recode missing values from the data if the model_type doesn't handle missing data
  if(model_type %in% c(1,3,5,7,9,11) & !is.na(idealdata@miss_val)) {
    Y <- na_if(Y,idealdata@miss_val)
  }
  
  #Remove NA values, which should have been coded correctly in the make_idealdata function
  
  remove_nas <- !is.na(Y)
  Y <- Y[remove_nas]
  legispoints <- legispoints[remove_nas]
  billpoints <- billpoints[remove_nas]
  timepoints <- timepoints[remove_nas]
  
  if(model_type>8) {
    N_cont <- length(Y)
    N_int <- 1
    Y_cont <- Y
    Y_int <- array(1L)
  } else {
    N_cont <- 1
    N_int <- length(Y)
    Y_cont <- array(1L)
    Y_int <- as.integer(Y)
  }
  
  this_data <- list(N=length(Y),
                    N_cont=N_cont,
                    N_int=N_int,
                    Y_int=Y_int,
                    Y_cont=Y_cont,
                    T=max(timepoints),
                    num_legis=as.integer(max(legispoints)),
                    num_bills=num_bills,
                    ll=legispoints,
                    bb=billpoints,
                    num_fix_high=as.integer(1),
                    num_fix_low=as.integer(1),
                    LX=dim(idealdata@person_cov)[3],
                    SRX=ncol(idealdata@item_cov),
                    SAX=ncol(idealdata@item_cov_miss),
                    legis_pred=legis_pred,
                    group_pred=idealdata@group_cov,
                    srx_pred=idealdata@item_cov,
                    sax_pred=idealdata@item_cov_miss,
                    time=timepoints,
                    model_type=model_type,
                    discrim_reg_sd=discrim_reg_sd,
                    discrim_abs_sd=discrim_miss_sd,
                    diff_reg_sd=diff_reg_sd,
                    diff_abs_sd=diff_miss_sd,
                    legis_sd=person_sd,
                    restrict_sd=restrict_sd,
                    restrict_low_bar=restrict_low_bar,
                    restrict_high_bar=restrict_high_bar,
                    use_ar=as.integer(use_ar),
                    diff=idealdata@diff,
                    diff_high=idealdata@diff_high,
                    time_sd=time_sd,
                    ar_sd=ar_sd)

  outobj <- sample_model(object=idealdata,nchains=nchains,niters=niters,warmup=warmup,ncores=ncores,
                         this_data=this_data,use_vb=use_vb,...)
  
  outobj@model_type <- model_type
  outobj@use_groups <- use_groups
  return(outobj)
  
}
